{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data set :: https://www.kaggle.com/datasets/sophatvathana/casia-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices: tf.config.experimental.set_memory_growth(device, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, Activation, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#converts input image to ela applied image\n",
    "def convert_to_ela_image(path,quality):\n",
    "\n",
    "    original_image = Image.open(path).convert('RGB')\n",
    "\n",
    "    #resaving input image at the desired quality\n",
    "    resaved_file_name = 'resaved_image.jpg'     #predefined filename for resaved image\n",
    "    original_image.save(resaved_file_name,'JPEG',quality=quality)\n",
    "    resaved_image = Image.open(resaved_file_name)\n",
    "\n",
    "    #pixel difference between original and resaved image\n",
    "    ela_image = ImageChops.difference(original_image,resaved_image)\n",
    "    \n",
    "    #scaling factors are calculated from pixel extremas\n",
    "    extrema = ela_image.getextrema()\n",
    "    max_difference = max([pix[1] for pix in extrema])\n",
    "    if max_difference ==0:\n",
    "        max_difference = 1\n",
    "    scale = 350.0 / max_difference\n",
    "    \n",
    "    #enhancing elaimage to brighten the pixels\n",
    "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "\n",
    "    ela_image.save(\"ela_image.png\")\n",
    "    return ela_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(image_path):\n",
    "    image_size = (128, 128)\n",
    "    return np.array(convert_to_ela_image(image_path, 90).resize(image_size)).flatten() / 255.0         #normalizing the array values obtained from input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # ELA converted images\n",
    "Y = [] # 0 for fake, 1 for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding authentic images\n",
    "\n",
    "path = ''       #folder path of the authentic images in the dataset\n",
    "for filename in tqdm(os.listdir(path),desc=\"Processing Images : \"):\n",
    "    if filename.endswith('jpg') or filename.endswith('png'):\n",
    "        full_path = os.path.join(path, filename)\n",
    "        X.append(prepare_image(full_path))        \n",
    "        Y.append(1)     # label for authentic images \n",
    "        \n",
    "print(f'Total images: {len(X)}\\nTotal labels: {len(Y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding forged images\n",
    "\n",
    "path = ''       #folder path of the forged images in the dataset\n",
    "for filename in tqdm(os.listdir(path),desc=\"Processing Images : \"):\n",
    "    if filename.endswith('jpg') or filename.endswith('png'):\n",
    "        full_path = os.path.join(path, filename)\n",
    "        X.append(prepare_image(full_path))        \n",
    "        Y.append(0)     # label for forged images \n",
    "        \n",
    "print(f'Total images: {len(X)}\\nTotal labels: {len(Y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X = X.reshape(-1, 128, 128, 3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning dataset for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training : Validation : Testing = 76 : 19 : 5\n",
    "X_temp, X_test, Y_temp, Y_test = train_test_split(X, Y, test_size = 0.05, random_state=5)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_temp, Y_temp, test_size = 0.2, random_state=5)\n",
    "X = X.reshape(-1,1,1,1)\n",
    "\n",
    "print(f'Training images: {len(X_train)} , Training labels: {len(Y_train)}')\n",
    "print(f'Validation images: {len(X_val)} , Validation labels: {len(Y_val)}')\n",
    "print(f'Test images: {len(X_test)} , Test labels: {len(Y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()  # Sequential Model\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (5, 5), padding = 'valid', activation = 'relu', input_shape = (128, 128, 3)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (5, 5), padding = 'valid', activation = 'relu'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (5, 5), padding = 'valid', activation = 'relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (5, 5), padding = 'valid', activation = 'relu'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (5, 5), padding = 'valid', activation = 'relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (5, 5), padding = 'valid', activation = 'relu'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'valid', activation = 'relu'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "init_lr = 1e-4   #learning rate for the optimizer\n",
    "optimizer = Adam(lr = init_lr, decay = init_lr/epochs) \n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early Stopping\n",
    "early_stopping = EarlyStopping(monitor = 'val_accuracy',\n",
    "                               min_delta = 0,\n",
    "                               patience = 10,\n",
    "                               verbose = 0,\n",
    "                               mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist = model.fit(X_train,\n",
    "                 Y_train,\n",
    "                 batch_size = batch_size,\n",
    "                 epochs = epochs,\n",
    "                 validation_data = (X_val, Y_val),\n",
    "                 callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model as a h5 file\n",
    "model.save('trained_model.h5') \n",
    "\n",
    "# get the dictionary containing each metric and the loss for each epoch\n",
    "history_dict = hist.history\n",
    "\n",
    "# save it as a json file\n",
    "json.dump(history_dict, open('metrics_dict', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the training and validation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "#Figure 1\n",
    "ax[0].plot(history_dict['loss'], color='b', label = \"Training loss\")\n",
    "ax[0].plot(history_dict['val_loss'], color='r', label = \"Validation loss\",axes =ax[0])\n",
    "ax[0].set_xlabel('Epochs',fontsize=16)\n",
    "ax[0].set_ylabel('Loss',fontsize=16)\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "#Figure 2\n",
    "ax[1].plot(history_dict['accuracy'], color='b', label = \"Training accuracy\")\n",
    "ax[1].plot(history_dict['val_accuracy'], color='r',label = \"Validation accuracy\")\n",
    "ax[1].set_xlabel('Epochs',fontsize=16)\n",
    "ax[1].set_ylabel('Accuracy',fontsize=16)\n",
    "legend = ax[1].legend(loc='best', shadow=True)\n",
    "\n",
    "fig.suptitle('Metrics',fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cf_matrix):\n",
    "  \n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()] #number of images in each classification block\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)] #percentage value of images in each block w.r.t total images\n",
    "\n",
    "    axes_labels=['Forged', 'Authentic']\n",
    "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cf_matrix, annot=labels, fmt='',cmap=\"flare\" , xticklabels=axes_labels, yticklabels=axes_labels)\n",
    "\n",
    "    plot_xlabel = plt.xlabel('Predicted labels', fontsize = 13)\n",
    "    plot_ylabel = plt.ylabel('True labels', fontsize = 13)\n",
    "    plot_title = plt.title('Confusion Matrix', fontsize= 10,fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_val)               # Predict the values from the validation dataset \n",
    "Y_pred_classes = np.round(Y_pred)           # roundoff the sigmoid value\n",
    "Y_true = Y_val                             \n",
    "\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)     # compute the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx)                         # plot the confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_true, Y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Forged', 'Authentic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Testing accuracy\n",
    "correct_test = 0 #correctly predicted test images\n",
    "total_test = 0   #total test images\n",
    "\n",
    "for index,image in enumerate(tqdm(X_test,desc=\"Processing Images : \")):\n",
    "    image = image.reshape(-1, 128, 128, 3)\n",
    "    y_pred = model.predict(image)\n",
    "    y_pred_class = np.round(y_pred)\n",
    "    total_test += 1\n",
    "    if y_pred_class == Y_test[index]: #if prediction is correct\n",
    "        correct_test += 1\n",
    "    \n",
    "print(f'Total test images: {total_test}\\nCorrectly predicted images: {correct_test}\\nAccuracy: {correct_test / total_test * 100.0} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = ''    # test image path\n",
    "test_image = prepare_image(test_image_path)\n",
    "test_image = test_image.reshape(-1, 128, 128, 3)\n",
    "\n",
    "y_pred = model.predict(test_image)\n",
    "y_pred_class = round(y_pred[0][0])\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(15,5)) \n",
    "\n",
    "#display original image\n",
    "original_image = plt.imread(test_image_path) \n",
    "ax[0].axis('off')\n",
    "ax[0].imshow(original_image)\n",
    "ax[0].set_title('Original Image')\n",
    "\n",
    "#display ELA applied image\n",
    "ax[1].axis('off')\n",
    "ax[1].imshow(convert_to_ela_image(test_image_path,90)) \n",
    "ax[1].set_title('ELA Image')\n",
    "\n",
    "print(f'Prediction: {class_names[y_pred_class]}')\n",
    "if y_pred<=0.5:\n",
    "    print(f'Confidence:  {(1-(y_pred[0][0])) * 100:0.2f}%')\n",
    "else:\n",
    "    print(f'Confidence: {(y_pred[0][0]) * 100:0.2f}%')\n",
    "print('--------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder_path = ''        #dataset path\n",
    "authentic,forged,total = 0,0,0\n",
    "\n",
    "for filename in tqdm(os.listdir(test_folder_path),desc=\"Processing Images : \"):\n",
    "    if filename.endswith('jpg') or filename.endswith('png'):\n",
    "        test_image_path = os.path.join(path, filename)\n",
    "        test_image = prepare_image(test_image_path)  \n",
    "        test_image.reshape(-1, 128, 128, 3)\n",
    "        y_pred = model.predict(image)\n",
    "        y_pred_class = np.round(y_pred)\n",
    "        total += 1\n",
    "        if y_pred_class == 0:\n",
    "            forged += 1\n",
    "        else:\n",
    "            authentic +=1\n",
    "\n",
    "print(f'Total images: {total}\\nAuthentic Images: {authentic}\\nForged Images: {forged}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
